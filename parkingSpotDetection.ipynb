{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "daniTesting.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVWxkXHFJ5GS"
      },
      "source": [
        "# References \n",
        "https://medium.com/the-research-nest/parking-space-detection-using-deep-learning-9fc99a63875e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Jv5LnrKPff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba42e5b-1845-46cd-ab83-38dc6a8befac"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 125.23 MiB | 34.09 MiB/s, done.\n",
            "Resolving deltas: 100% (562/562), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSmDt9l9gFaJ",
        "outputId": "a208aea0-914d-482c-87c5-a31c2ded16b4"
      },
      "source": [
        "%tensorflow_version 1.15.\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QICzUjNeg-C-",
        "outputId": "81691386-eb94-43f0-de65-f54a477177a3"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Tensorflow Version: \", tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version:  1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WTgIMrCKFX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118c7b9a-24c6-4d40-c90e-997ef826bc51"
      },
      "source": [
        "import os\n",
        "os.chdir(\"Mask_RCNN/\")\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mrcnn.config\n",
        "import mrcnn.utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pickle\n",
        "\n",
        "from shapely.geometry import box\n",
        "from shapely.geometry import Polygon as shapely_poly\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "import io\n",
        "import base64\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVHZFzubKQ6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c2ea63-4c65-47c4-a89a-fa7f759b5141"
      },
      "source": [
        "class Config(mrcnn.config.Config):\n",
        "    NAME = \"coco_pretrained_model_config\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    GPU_COUNT = 1\n",
        "    NUM_CLASSES = 81\n",
        "\n",
        "config = Config()\n",
        "config.display()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                93\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco_pretrained_model_config\n",
            "NUM_CLASSES                    81\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O2GxDQ4KStn"
      },
      "source": [
        "ROOT_DIR = Path(\".\")\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsqyjjY4KVUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8106e9cb-287e-4473-df59-b922a50f3cbe"
      },
      "source": [
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pretrained model to ./mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxljUlaHKW8g",
        "outputId": "8f99048e-24af-4bb6-d69b-a6d6c24382fb"
      },
      "source": [
        "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=Config())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbsW6iZJhQtB"
      },
      "source": [
        "\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFJy859phVVd"
      },
      "source": [
        "#  This will contain test videos and images\n",
        "if not os.path.exists(\"./data\"):\n",
        "    os.makedirs(\"./data\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3ZAq6RsiQ8-"
      },
      "source": [
        "left off here\n",
        "\n",
        "> I'M OUT OF ROOM ON MY LAPTOP TO DOWNLOAD THE VIDEO TO UPLOAD IT HERE \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO3RHQLlhZO5"
      },
      "source": [
        "VIDEO_SOURCE = \"data/parking1.mp4\"\n",
        "PARKING_REGIONS = \"data/regions1.p\"\n",
        "with open(PARKING_REGIONS, 'rb') as f:\n",
        "    parked_car_boxes = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7NNe0CviG4H"
      },
      "source": [
        "def get_car_boxes(boxes, class_ids):\n",
        "    car_boxes = []\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        # If the detected object isn't a car / truck, skip it\n",
        "        if class_ids[i] in [3, 8, 6]:\n",
        "            car_boxes.append(box)\n",
        "\n",
        "    return np.array(car_boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmN0x0G1iIGj"
      },
      "source": [
        "def compute_overlaps(parked_car_boxes, car_boxes):\n",
        "    \n",
        "    new_car_boxes = []\n",
        "    for box in car_boxes:\n",
        "        y1 = box[0]\n",
        "        x1 = box[1]\n",
        "        y2 = box[2]\n",
        "        x2 = box[3]\n",
        "        \n",
        "        p1 = (x1, y1)\n",
        "        p2 = (x2, y1)\n",
        "        p3 = (x2, y2)\n",
        "        p4 = (x1, y2)\n",
        "        new_car_boxes.append([p1, p2, p3, p4])\n",
        "    \n",
        "    overlaps = np.zeros((len(parked_car_boxes), len(new_car_boxes)))\n",
        "    for i in range(len(parked_car_boxes)):\n",
        "        for j in range(car_boxes.shape[0]):\n",
        "            pol1_xy = parked_car_boxes[i]\n",
        "            pol2_xy = new_car_boxes[j]\n",
        "            polygon1_shape = shapely_poly(pol1_xy)\n",
        "            polygon2_shape = shapely_poly(pol2_xy)\n",
        "\n",
        "            polygon_intersection = polygon1_shape.intersection(polygon2_shape).area\n",
        "            polygon_union = polygon1_shape.union(polygon2_shape).area\n",
        "            IOU = polygon_intersection / polygon_union\n",
        "            overlaps[i][j] = IOU\n",
        "\n",
        "    return overlaps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsbYVQsxiLyw"
      },
      "source": [
        "def arrayShow (imageArray):\n",
        "    ret, png = cv2.imencode('.png', imageArray)\n",
        "    encoded = base64.b64encode(png)\n",
        "    return Image(data=encoded.decode('ascii'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5DYREVOiOVz"
      },
      "source": [
        "alpha = 0.6\n",
        "video_capture = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "cnt=0\n",
        "\n",
        "video_FourCC    = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "video_fps       = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "video_size      = (int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                    int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "out = cv2.VideoWriter(\"out.avi\", video_FourCC, video_fps, video_size)\n",
        "\n",
        "while video_capture.isOpened():\n",
        "    success, frame = video_capture.read()\n",
        "    overlay = frame.copy()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    rgb_image = frame[:, :, ::-1]\n",
        "    results = model.detect([rgb_image], verbose=0)\n",
        "\n",
        "    car_boxes = get_car_boxes(results[0]['rois'], results[0]['class_ids'])\n",
        "    overlaps = compute_overlaps(parked_car_boxes, car_boxes)\n",
        "\n",
        "    for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
        "        max_IoU_overlap = np.max(overlap_areas)\n",
        "        if max_IoU_overlap < 0.15:\n",
        "            cv2.fillPoly(overlay, [np.array(parking_area)], (71, 27, 92))\n",
        "            free_space = True      \n",
        "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    img = arrayShow(frame)\n",
        "    display(img)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}